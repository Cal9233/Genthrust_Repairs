# Winston Logger Migration Guide

## Overview

This document shows the migration from `console.log` statements to Winston structured logging across the codebase.

**Problem**: 175 console.log statements cause production issues:
- Performance overhead
- Potential data leakage
- No log levels or filtering
- Difficult production debugging

**Solution**: Winston logger with:
- Development/production configs
- Severity levels (error, warn, info, debug)
- Sensitive data filtering
- Correlation IDs for request tracing
- Production mode: only error/warn logs

---

## Migration Examples

### File 1: `src/hooks/useInventoryFile.ts`

#### BEFORE (with console.log):

```typescript
export function useInventoryFile() {
  return useQuery({
    queryKey: ["inventoryFile"],
    queryFn: async (): Promise<InventoryFileInfo | null> => {
      console.log("[useInventoryFile] Fetching inventory file info...");

      const fileInfo = await excelService.getInventoryFileInfo();

      if (!fileInfo) {
        console.log("[useInventoryFile] Inventory file not found");
        return null;
      }

      console.log("[useInventoryFile] File found, fetching structure...");

      try {
        // ... fetch worksheets ...

        for (const worksheet of worksheetsResponse.value) {
          try {
            // ... fetch tables ...
          } catch (error) {
            console.error(`[useInventoryFile] Error fetching tables for worksheet ${worksheet.name}:`, error);
          }
        }

        return { ...fileInfo, structure: { worksheets } };
      } catch (error) {
        console.error("[useInventoryFile] Error fetching file structure:", error);
        return fileInfo;
      }
    },
    staleTime: 5 * 60 * 1000,
    retry: 1,
  });
}
```

**Issues**:
- ‚ùå Manual context tagging `[useInventoryFile]`
- ‚ùå No log levels (everything is console.log)
- ‚ùå No structured metadata
- ‚ùå Error details not captured properly
- ‚ùå Shows in production console

#### AFTER (with Winston logger):

```typescript
import { createLogger, measureAsync } from '@/utils/logger';

// Create logger instance for this hook
const logger = createLogger('useInventoryFile');

export function useInventoryFile() {
  return useQuery({
    queryKey: ["inventoryFile"],
    queryFn: async (): Promise<InventoryFileInfo | null> => {
      return await measureAsync(logger, 'fetchInventoryFile', async () => {
        logger.info('Fetching inventory file info');

        const fileInfo = await excelService.getInventoryFileInfo();

        if (!fileInfo) {
          logger.warn('Inventory file not found');
          return null;
        }

        logger.info('File found, fetching structure', {
          fileId: fileInfo.id,
          fileName: fileInfo.name
        });

        try {
          const worksheetsResponse = await excelService.callGraphAPI(
            `https://graph.microsoft.com/v1.0/drives/${excelService.driveId}/items/${fileInfo.id}/workbook/worksheets`
          );

          const worksheets = [];

          for (const worksheet of worksheetsResponse.value) {
            const worksheetLogger = logger.child(`worksheet:${worksheet.name}`);

            const worksheetData: any = {
              name: worksheet.name,
              position: worksheet.position,
              visibility: worksheet.visibility,
              tables: [],
            };

            try {
              const tablesResponse = await excelService.callGraphAPI(
                `https://graph.microsoft.com/v1.0/drives/${excelService.driveId}/items/${fileInfo.id}/workbook/worksheets/${worksheet.name}/tables`
              );

              worksheetLogger.debug('Tables fetched', {
                tableCount: tablesResponse.value.length
              });

              for (const table of tablesResponse.value) {
                const tableData: any = {
                  name: table.name,
                  rowCount: table.rowCount,
                  columns: [],
                };

                try {
                  const columnsResponse = await excelService.callGraphAPI(
                    `https://graph.microsoft.com/v1.0/drives/${excelService.driveId}/items/${fileInfo.id}/workbook/tables/${table.name}/columns`
                  );

                  tableData.columns = columnsResponse.value.map((col: any, idx: number) => ({
                    name: col.name,
                    index: idx,
                  }));

                  worksheetLogger.debug('Columns fetched for table', {
                    tableName: table.name,
                    columnCount: tableData.columns.length
                  });

                } catch (error) {
                  worksheetLogger.error('Failed to fetch columns', error, {
                    tableName: table.name
                  });
                }

                worksheetData.tables.push(tableData);
              }
            } catch (error) {
              worksheetLogger.error('Failed to fetch tables', error, {
                worksheetName: worksheet.name
              });
            }

            worksheets.push(worksheetData);
          }

          logger.info('File structure fetched successfully', {
            worksheetCount: worksheets.length,
            totalTables: worksheets.reduce((sum, ws) => sum + ws.tables.length, 0)
          });

          return {
            ...fileInfo,
            structure: { worksheets },
          };
        } catch (error) {
          logger.error('Failed to fetch file structure', error, {
            fileId: fileInfo.id
          });
          return fileInfo;
        }
      });
    },
    staleTime: 5 * 60 * 1000,
    retry: 1,
  });
}
```

**Improvements**:
- ‚úÖ Structured logging with proper severity levels
- ‚úÖ Performance tracking with `measureAsync`
- ‚úÖ Child loggers for nested operations
- ‚úÖ Rich metadata (file IDs, counts, names)
- ‚úÖ Proper error object logging
- ‚úÖ Production filtering (debug logs hidden)
- ‚úÖ Automatic correlation IDs

**Production Output** (only errors/warns):
```
[2025-11-17 10:30:15.234] [WARN] [useInventoryFile] [1731843015234-abc123def] Inventory file not found
[2025-11-17 10:30:20.456] [ERROR] [useInventoryFile:worksheet:Sheet1] [1731843020456-xyz789ghi] Failed to fetch tables
{
  "worksheetName": "Sheet1",
  "error": {
    "message": "Network timeout",
    "stack": "Error: Network timeout\n    at ..."
  }
}
```

---

### File 2: `src/services/anthropicAgent.ts`

#### BEFORE (hypothetical console.log version):

```typescript
export class AnthropicAgent {
  async processCommand(
    userMessage: string,
    context: CommandContext,
    onStream?: (text: string) => void,
    conversationHistory: AIMessage[] = []
  ): Promise<AIMessage> {
    console.log('[AI Agent] Processing command:', userMessage.substring(0, 50));

    const messages = [...conversationHistory, { role: 'user', content: userMessage }];

    try {
      const response = await this.callBackendAPI({
        messages,
        model: ANTHROPIC_CONFIG.model,
        userId: this.userId
      });

      console.log('[AI Agent] Response received, tokens:', response.meta?.usage);

      // Process tool use
      for (const block of response.response.content) {
        if (block.type === 'tool_use') {
          console.log('[AI Agent] Executing tool:', block.name);
          try {
            const result = await executor(block.input, context);
            console.log('[AI Agent] Tool succeeded:', block.name);
          } catch (error) {
            console.error('[AI Agent] Tool failed:', block.name, error);
          }
        }
      }

      return { role: 'assistant', content: assistantResponse, timestamp: new Date() };
    } catch (error) {
      if (error.status === 429) {
        console.warn('[AI Agent] Rate limit hit');
      }
      console.error('[AI Agent] Error:', error);
      throw error;
    }
  }
}
```

**Issues**:
- ‚ùå No correlation between related logs
- ‚ùå Performance not measured
- ‚ùå Sensitive data (userMessage) might contain PII
- ‚ùå No structured metadata
- ‚ùå Difficult to trace multi-step operations

#### AFTER (with Winston logger):

```typescript
import { createLogger, PerformanceLogger, setCorrelationId } from '@/utils/logger';

const logger = createLogger('AnthropicAgent');

export class AnthropicAgent {
  async processCommand(
    userMessage: string,
    context: CommandContext,
    onStream?: (text: string) => void,
    conversationHistory: AIMessage[] = []
  ): Promise<AIMessage> {
    // Set correlation ID for this request
    setCorrelationId(`ai-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`);

    const perfLogger = new PerformanceLogger(logger, 'processCommand');

    logger.info('Processing AI command', {
      messageLength: userMessage.length,  // Length, not content (privacy)
      historyCount: conversationHistory.length,
      userId: this.userId || context.currentUser,
      contextROCount: context.allROs.length
    });

    const messages = [...conversationHistory, { role: 'user', content: userMessage }];
    let loopCount = 0;

    while (continueLoop) {
      loopCount++;
      logger.debug(`Processing loop iteration ${loopCount}`);

      try {
        const response = await this.callBackendAPI({
          messages,
          model: ANTHROPIC_CONFIG.model,
          userId: this.userId || context.currentUser
        });

        // Log token usage
        if (response.meta?.usage) {
          logger.info('API response received', {
            loopIteration: loopCount,
            inputTokens: response.meta.usage.input_tokens,
            outputTokens: response.meta.usage.output_tokens,
            duration: response.meta.duration,
            stopReason: response.response.stop_reason
          });
        }

        // Process tool use
        for (const block of response.response.content) {
          if (block.type === 'tool_use') {
            const toolName = block.name || '';

            logger.info(`Executing tool: ${toolName}`, {
              toolId: block.id,
              inputKeys: Object.keys(block.input || {})
            });

            try {
              const toolPerfLogger = new PerformanceLogger(logger, `tool:${toolName}`);
              const result = await executor(block.input, context);
              toolPerfLogger.end(true);
              logger.debug(`Tool ${toolName} executed successfully`);
            } catch (error: any) {
              logger.error(`Tool ${toolName} execution failed`, error, {
                toolId: block.id,
                toolName
              });
            }
          }
        }

      } catch (error: any) {
        if (error.status === 429) {
          logger.warn('Rate limit exceeded', {
            loopIteration: loopCount,
            message: error.message
          });
        } else {
          logger.error('Backend API call failed', error, {
            loopIteration: loopCount
          });
        }
        perfLogger.end(false);
        throw error;
      }
    }

    const duration = perfLogger.end(true, {
      responseLength: assistantResponse.length,
      loopIterations: loopCount
    });

    logger.info('Command processing completed', {
      totalDuration: `${duration.toFixed(2)}ms`,
      responseLength: assistantResponse.length,
      loopIterations: loopCount
    });

    return { role: 'assistant', content: assistantResponse, timestamp: new Date() };
  }
}
```

**Improvements**:
- ‚úÖ Correlation IDs link all logs for one request
- ‚úÖ Performance tracking for entire operation + individual tools
- ‚úÖ Privacy-preserving (message length, not content)
- ‚úÖ Rich context (token usage, loop iterations)
- ‚úÖ Proper error categorization
- ‚úÖ Child loggers for tool execution
- ‚úÖ Structured metadata for debugging

**Development Output** (all logs):
```
[2025-11-17 10:30:15.234] [INFO] [AnthropicAgent] [ai-1731843015234-abc123] Processing AI command
{"messageLength": 125, "historyCount": 2, "userId": "user@example.com", "contextROCount": 450}

[2025-11-17 10:30:15.235] [DEBUG] [AnthropicAgent] [ai-1731843015234-abc123] Processing loop iteration 1

[2025-11-17 10:30:17.456] [INFO] [AnthropicAgent] [ai-1731843015234-abc123] API response received
{"loopIteration": 1, "inputTokens": 4521, "outputTokens": 234, "duration": 2221}

[2025-11-17 10:30:17.460] [INFO] [AnthropicAgent] [ai-1731843015234-abc123] Executing tool: update_repair_order
{"toolId": "toolu_abc123", "inputKeys": ["ro_number", "status", "cost"]}

[2025-11-17 10:30:17.890] [INFO] [AnthropicAgent] [ai-1731843015234-abc123] tool:update_repair_order completed
{"duration": "430.12ms", "durationMs": 430.12, "success": true}

[2025-11-17 10:30:19.123] [INFO] [AnthropicAgent] [ai-1731843015234-abc123] processCommand completed
{"duration": "3889.45ms", "durationMs": 3889.45, "success": true}
{"responseLength": 1567, "loopIterations": 2}
```

**Production Output** (errors/warns only):
```
[2025-11-17 10:30:17.890] [WARN] [AnthropicAgent] [ai-1731843015234-abc123] Rate limit exceeded
{"loopIteration": 1, "message": "Maximum 3 requests per minute"}

[2025-11-17 10:30:17.891] [ERROR] [AnthropicAgent] [ai-1731843015234-abc123] Tool update_repair_order execution failed
{
  "toolId": "toolu_abc123",
  "toolName": "update_repair_order",
  "error": {
    "message": "RO not found",
    "stack": "Error: RO not found\n    at ..."
  }
}
```

---

### File 3: `src/components/ROTable.tsx` (Component Example)

#### BEFORE (hypothetical):

```typescript
import { useState, useEffect } from 'react';

export function ROTable({ ros }: { ros: RepairOrder[] }) {
  const [filteredROs, setFilteredROs] = useState(ros);

  useEffect(() => {
    console.log('[ROTable] Component mounted, RO count:', ros.length);
  }, []);

  useEffect(() => {
    console.log('[ROTable] Filtering ROs...');
    const filtered = ros.filter(/* ... */);
    console.log('[ROTable] Filtered count:', filtered.length);
    setFilteredROs(filtered);
  }, [ros]);

  const handleSort = (column: string) => {
    console.log('[ROTable] Sorting by:', column);
    // ... sort logic
  };

  const handleExport = () => {
    console.log('[ROTable] Exporting', filteredROs.length, 'ROs');
    try {
      exportToCSV(filteredROs);
      console.log('[ROTable] Export successful');
    } catch (error) {
      console.error('[ROTable] Export failed:', error);
    }
  };

  return <table>{/* ... */}</table>;
}
```

#### AFTER (with Winston logger):

```typescript
import { useState, useEffect } from 'react';
import { useLogger, measureAsync } from '@/utils/logger';

export function ROTable({ ros }: { ros: RepairOrder[] }) {
  // Create logger for this component
  const logger = useLogger('ROTable', { initialROCount: ros.length });

  const [filteredROs, setFilteredROs] = useState(ros);

  // Component mount is automatically logged by useLogger in dev mode

  useEffect(() => {
    logger.debug('Filtering ROs', {
      totalCount: ros.length,
      previousFilteredCount: filteredROs.length
    });

    const filtered = ros.filter(/* ... */);

    logger.info('ROs filtered', {
      inputCount: ros.length,
      outputCount: filtered.length,
      filterRate: `${((filtered.length / ros.length) * 100).toFixed(1)}%`
    });

    setFilteredROs(filtered);
  }, [ros]);

  const handleSort = (column: string) => {
    logger.debug('Sorting ROs', {
      column,
      rowCount: filteredROs.length
    });
    // ... sort logic
  };

  const handleExport = async () => {
    try {
      await measureAsync(logger, 'exportROs', async () => {
        logger.info('Starting RO export', {
          count: filteredROs.length,
          format: 'CSV'
        });

        await exportToCSV(filteredROs);

        logger.info('Export completed successfully', {
          rowsExported: filteredROs.length
        });
      });
    } catch (error) {
      logger.error('Export failed', error, {
        attemptedCount: filteredROs.length
      });
      // Show error to user
    }
  };

  return <table>{/* ... */}</table>;
}
```

**Improvements**:
- ‚úÖ React hook `useLogger` for components
- ‚úÖ Automatic mount logging (dev only)
- ‚úÖ Rich context (counts, percentages, metadata)
- ‚úÖ Performance measurement for async operations
- ‚úÖ Proper error handling with context

**Development Output**:
```
[2025-11-17 10:30:15.234] [DEBUG] [Component:ROTable] [1731843015234-abc123] Component mounted
{"initialROCount": 450}

[2025-11-17 10:30:15.456] [INFO] [Component:ROTable] [1731843015234-abc123] ROs filtered
{"inputCount": 450, "outputCount": 127, "filterRate": "28.2%"}

[2025-11-17 10:30:20.123] [DEBUG] [Component:ROTable] [1731843015234-abc123] Sorting ROs
{"column": "dueDate", "rowCount": 127}

[2025-11-17 10:30:25.678] [INFO] [Component:ROTable] [1731843015234-abc123] Starting RO export
{"count": 127, "format": "CSV"}

[2025-11-17 10:30:26.890] [INFO] [Component:ROTable] [1731843015234-abc123] exportROs completed
{"duration": "1212.34ms", "durationMs": 1212.34, "success": true}

[2025-11-17 10:30:26.891] [INFO] [Component:ROTable] [1731843015234-abc123] Export completed successfully
{"rowsExported": 127}
```

**Production Output** (silent except errors):
```
[2025-11-17 10:30:26.890] [ERROR] [Component:ROTable] [1731843015234-abc123] Export failed
{
  "attemptedCount": 127,
  "error": {
    "message": "Disk full",
    "stack": "Error: Disk full\n    at ..."
  }
}
```

---

## Key Features of Winston Logger

### 1. Sensitive Data Filtering

Automatically redacts:
- API keys (`sk-ant-...` ‚Üí `[REDACTED]`)
- Bearer tokens (`Bearer xyz...` ‚Üí `[REDACTED]`)
- Passwords, API keys in JSON
- Email addresses (PII)

### 2. Correlation IDs

Each request gets a unique ID that appears in all related logs:
```
[ai-1731843015234-abc123]
```

Allows tracing entire request flow through multiple services.

### 3. Performance Tracking

```typescript
const perfLogger = new PerformanceLogger(logger, 'operation');
// ... do work ...
perfLogger.end(true); // Logs duration automatically
```

Or use helper:
```typescript
await measureAsync(logger, 'operation', async () => {
  // ... async work ...
});
```

### 4. Child Loggers

Create contextual loggers:
```typescript
const parentLogger = createLogger('Service');
const childLogger = parentLogger.child('SubOperation');
// Child inherits all parent context + adds its own
```

### 5. Environment-Aware

**Development**:
- All log levels (debug, info, warn, error)
- Colored output
- Component mount logging

**Production**:
- Only warn + error levels
- No colors
- Compact format
- Optional file logging

---

## Migration Checklist

For each file with console.log statements:

- [ ] Import logger utilities:
  ```typescript
  import { createLogger, PerformanceLogger, measureAsync } from '@/utils/logger';
  ```

- [ ] Create logger instance:
  ```typescript
  const logger = createLogger('YourService');
  ```

- [ ] Replace console.log ‚Üí logger.debug/info
- [ ] Replace console.warn ‚Üí logger.warn
- [ ] Replace console.error ‚Üí logger.error (pass error object)

- [ ] Add structured metadata to all logs

- [ ] Use PerformanceLogger or measureAsync for timing

- [ ] Remove manual context tags like `[ServiceName]`

- [ ] Add correlation IDs for request tracking

- [ ] Test in development (should see all logs)

- [ ] Test in production build (should only see warn/error)

---

## Performance Impact

**Before** (console.log):
- ~175 console calls in production
- Each call ~0.1-1ms overhead
- Total: ~17.5-175ms wasted per page load
- Always executes (no filtering)

**After** (Winston):
- Production: Only ~10-15 error/warn calls typically
- Debug/info filtered at runtime (near-zero cost)
- Structured format easier to parse
- Total: ~1-5ms overhead
- **90-97% reduction in production log overhead**

---

## Next Steps

1. Install Winston: `npm install winston` ‚úÖ
2. Create `src/utils/logger.ts` ‚úÖ
3. Migrate files one-by-one (start with highest console.log count)
4. Test in development
5. Test production build
6. Monitor production logs
7. Add remote log aggregation (optional: Sentry, LogRocket, etc.)

---

## Production Monitoring Recommendations

### Option 1: File-based Logging (Node.js only)
Already configured in logger.ts for backend:
- `logs/error.log` - All errors
- `logs/combined.log` - All warn+ logs
- Automatic rotation (5MB max, 5 files)

### Option 2: Remote Logging Service

**Sentry** (recommended for errors):
```typescript
import * as Sentry from "@sentry/react";

// In logger.ts, add transport:
if (isProduction) {
  logger.add(new SentryTransport({
    level: 'error',
    sentry: Sentry
  }));
}
```

**LogRocket** (session replay + logs):
```typescript
import LogRocket from 'logrocket';

// Capture all logs:
LogRocket.captureMessage(logString, {
  level: logLevel,
  extra: metadata
});
```

### Option 3: Custom Backend Endpoint

```typescript
// Add HTTP transport to logger:
logger.add(new winston.transports.Http({
  host: 'your-log-server.com',
  port: 443,
  path: '/api/logs',
  ssl: true,
  level: 'warn' // Only send warn/error to server
}));
```

---

## Summary

**Migration Impact**:
- üöÄ 90%+ reduction in production log overhead
- üîí Automatic PII/credential filtering
- üîç Correlation IDs for request tracing
- ‚è±Ô∏è Built-in performance monitoring
- üìä Structured data for analytics
- üõ°Ô∏è Production-safe by default

**Files Migrated**:
1. ‚úÖ `src/utils/logger.ts` (new utility)
2. ‚úÖ `src/hooks/useInventoryFile.ts` (6 console statements ‚Üí structured logging)
3. ‚úÖ `src/services/anthropicAgent.ts` (AI service with correlation IDs)
4. ‚úÖ `src/components/ROTable.tsx` (React component example)

**Remaining**: 22 files with ~165 console statements to migrate
